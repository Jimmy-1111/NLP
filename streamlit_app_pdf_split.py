import streamlit as st
import pdfplumber
import pandas as pd
import re
import io

def split_sentences(text):
    if not text:
        return []

    lines = text.splitlines()
    merged_lines = []
    buffer = ""

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # ä¸»æ¨™æˆ–æ¢åˆ—æ¨™é¡Œï¼šä¿ç•™ç¨ç«‹å¥
        if re.match(r'^\d{1,2}[ ã€€]*ã€.+ã€‘$', line) or re.match(r'^[(ï¼ˆ][0-9ï¼-ï¼™]{1,3}[)ï¼‰]', line):
            if buffer:
                merged_lines.append(buffer)
                buffer = ""
            merged_lines.append(line)
            continue

        if buffer:
            if (
                not re.search(r'[ã€‚ï¼ï¼ï¼Ÿ]$', buffer)
                and re.match(r'^[ã-ã‚“ã‚¡-ãƒ³a-zï¼¡-ï¼ºï½-ï½šä¸€-é¾¯A-Zï¼ˆ(ã€ã€Œã€]', line)
            ):
                buffer += line
            else:
                merged_lines.append(buffer)
                buffer = line
        else:
            buffer = line

    if buffer:
        merged_lines.append(buffer)

    split_by_punctuation = []
    for line in merged_lines:
        if re.match(r'^[(ï¼ˆ]?[0-9ï¼-ï¼™]{1,3}[)ï¼‰]?.*$', line):
            split_by_punctuation.append(line)
        else:
            segments = re.split(r'(ã€‚)', line)
            sentence = ""
            for seg in segments:
                if seg == "ã€‚":
                    sentence += seg
                    if sentence.strip():
                        split_by_punctuation.append(sentence.strip())
                        sentence = ""
                else:
                    sentence += seg
            if sentence.strip():
                split_by_punctuation.append(sentence.strip())

    exclude_keywords = [
        "EDINETæå‡ºæ›¸é¡",
        "æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸",
        re.compile(r'.+æ ªå¼ä¼šç¤¾\(E\d{5}\)'),
        re.compile(r'^\d{1,3}/\d{1,3}$')
    ]

    sentences = []
    for s in split_by_punctuation:
        exclude = False
        for kw in exclude_keywords:
            if isinstance(kw, str) and kw in s:
                exclude = True
                break
            elif isinstance(kw, re.Pattern) and kw.search(s):
                exclude = True
                break
        if not exclude:
            sentences.append(s)

    return sentences

def main():
    st.title("PDF èªå¥åˆ†å‰²å™¨")
    st.write("ä¸Šå‚³ PDF ä¸¦æŒ‡å®šé ç¢¼ç¯„åœï¼Œåˆ†å¥å¾Œå¯ä¸‹è¼‰ Excel æª”ã€‚")

    pdf_file = st.file_uploader("è«‹ä¸Šå‚³ PDF æª”æ¡ˆ", type="pdf")
    start_page = st.number_input("é–‹å§‹é ç¢¼ï¼ˆå¾ 1 èµ·ç®—ï¼‰", min_value=1, step=1)
    end_page = st.number_input("çµæŸé ç¢¼ï¼ˆåŒ…å«ï¼‰", min_value=1, step=1)

    if pdf_file and end_page >= start_page:
        st.info("â³ æ­£åœ¨è™•ç† PDFï¼Œè«‹ç¨å€™...")
        data = []
        with pdfplumber.open(pdf_file) as pdf:
            for i in range(start_page - 1, end_page):
                if i < len(pdf.pages):
                    page = pdf.pages[i]
                    text = page.extract_text()
                    sentences = split_sentences(text)
                    if sentences and re.match(r'^\d{1,3}/\d{1,3}$', sentences[0]):
                        sentences = sentences[1:]
                    for idx, s in enumerate(sentences, 1):
                        data.append({"é ç¢¼": i+1, "èªå¥ç·¨è™Ÿ": idx, "èªå¥å…§å®¹": s})

        df = pd.DataFrame(data)
        st.success("âœ… åˆ†å¥å®Œæˆï¼é è¦½å¦‚ä¸‹ï¼š")
        st.dataframe(df, use_container_width=True)

        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False)
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Excel æª”",
            data=output.getvalue(),
            file_name="pdf_sentences.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

if __name__ == '__main__':
    main()
